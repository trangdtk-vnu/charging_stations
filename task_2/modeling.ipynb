{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, balanced_accuracy_score\n",
    "from sklearn.utils import all_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"D:\\BIG_DATA\\charging_stations\\task_2\\AllCity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geometry</th>\n",
       "      <td>POLYGON ((494324.36910769687 4140139.900782528...</td>\n",
       "      <td>POLYGON ((494491.37794651155 4140530.022613017...</td>\n",
       "      <td>POLYGON ((494705.80941380473 4141022.185615587...</td>\n",
       "      <td>POLYGON ((494818.1755447965 4140037.859610446,...</td>\n",
       "      <td>POLYGON ((494818.17554479634 4141263.137357092...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EV_stations_counts</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EV_stations_geomery</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>landuse</th>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nodes</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edges</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oneway_exists</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>highway_types</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_lanes</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_maxspeed</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <td>Catania</td>\n",
       "      <td>Catania</td>\n",
       "      <td>Catania</td>\n",
       "      <td>Catania</td>\n",
       "      <td>Catania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>school_count</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>university_count</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restaurant_count</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place_of_worship_count</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>community_centre_count</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>townhall_count</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parking_count</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>library_count</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>park_count</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commercial_count</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>government_count</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>civic_count</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retail_count</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        0  \\\n",
       "Unnamed: 0                                                              0   \n",
       "geometry                POLYGON ((494324.36910769687 4140139.900782528...   \n",
       "EV_stations_counts                                                      0   \n",
       "EV_stations_geomery                                                    []   \n",
       "population                                                            0.0   \n",
       "landuse                                                             Other   \n",
       "nodes                                                                   0   \n",
       "edges                                                                   0   \n",
       "density                                                               0.0   \n",
       "oneway_exists                                                          No   \n",
       "highway_types                                                         NaN   \n",
       "average_lanes                                                         NaN   \n",
       "average_maxspeed                                                      NaN   \n",
       "city                                                              Catania   \n",
       "school_count                                                          NaN   \n",
       "university_count                                                      NaN   \n",
       "restaurant_count                                                      NaN   \n",
       "place_of_worship_count                                                NaN   \n",
       "community_centre_count                                                NaN   \n",
       "townhall_count                                                        NaN   \n",
       "parking_count                                                         NaN   \n",
       "library_count                                                         NaN   \n",
       "park_count                                                            NaN   \n",
       "commercial_count                                                      NaN   \n",
       "government_count                                                      NaN   \n",
       "civic_count                                                           NaN   \n",
       "retail_count                                                          NaN   \n",
       "\n",
       "                                                                        1  \\\n",
       "Unnamed: 0                                                              1   \n",
       "geometry                POLYGON ((494491.37794651155 4140530.022613017...   \n",
       "EV_stations_counts                                                      0   \n",
       "EV_stations_geomery                                                    []   \n",
       "population                                                            0.0   \n",
       "landuse                                                             Other   \n",
       "nodes                                                                   0   \n",
       "edges                                                                   0   \n",
       "density                                                               0.0   \n",
       "oneway_exists                                                          No   \n",
       "highway_types                                                         NaN   \n",
       "average_lanes                                                         NaN   \n",
       "average_maxspeed                                                      NaN   \n",
       "city                                                              Catania   \n",
       "school_count                                                          NaN   \n",
       "university_count                                                      NaN   \n",
       "restaurant_count                                                      NaN   \n",
       "place_of_worship_count                                                NaN   \n",
       "community_centre_count                                                NaN   \n",
       "townhall_count                                                        NaN   \n",
       "parking_count                                                         NaN   \n",
       "library_count                                                         NaN   \n",
       "park_count                                                            NaN   \n",
       "commercial_count                                                      NaN   \n",
       "government_count                                                      NaN   \n",
       "civic_count                                                           NaN   \n",
       "retail_count                                                          NaN   \n",
       "\n",
       "                                                                        2  \\\n",
       "Unnamed: 0                                                              2   \n",
       "geometry                POLYGON ((494705.80941380473 4141022.185615587...   \n",
       "EV_stations_counts                                                      0   \n",
       "EV_stations_geomery                                                    []   \n",
       "population                                                            0.0   \n",
       "landuse                                                             Other   \n",
       "nodes                                                                   0   \n",
       "edges                                                                   0   \n",
       "density                                                               0.0   \n",
       "oneway_exists                                                          No   \n",
       "highway_types                                                         NaN   \n",
       "average_lanes                                                         NaN   \n",
       "average_maxspeed                                                      NaN   \n",
       "city                                                              Catania   \n",
       "school_count                                                          NaN   \n",
       "university_count                                                      NaN   \n",
       "restaurant_count                                                      NaN   \n",
       "place_of_worship_count                                                NaN   \n",
       "community_centre_count                                                NaN   \n",
       "townhall_count                                                        NaN   \n",
       "parking_count                                                         NaN   \n",
       "library_count                                                         NaN   \n",
       "park_count                                                            NaN   \n",
       "commercial_count                                                      NaN   \n",
       "government_count                                                      NaN   \n",
       "civic_count                                                           NaN   \n",
       "retail_count                                                          NaN   \n",
       "\n",
       "                                                                        3  \\\n",
       "Unnamed: 0                                                              3   \n",
       "geometry                POLYGON ((494818.1755447965 4140037.859610446,...   \n",
       "EV_stations_counts                                                      0   \n",
       "EV_stations_geomery                                                    []   \n",
       "population                                                            0.0   \n",
       "landuse                                                             Other   \n",
       "nodes                                                                   0   \n",
       "edges                                                                   0   \n",
       "density                                                               0.0   \n",
       "oneway_exists                                                          No   \n",
       "highway_types                                                         NaN   \n",
       "average_lanes                                                         NaN   \n",
       "average_maxspeed                                                      NaN   \n",
       "city                                                              Catania   \n",
       "school_count                                                          NaN   \n",
       "university_count                                                      NaN   \n",
       "restaurant_count                                                      NaN   \n",
       "place_of_worship_count                                                NaN   \n",
       "community_centre_count                                                NaN   \n",
       "townhall_count                                                        NaN   \n",
       "parking_count                                                         NaN   \n",
       "library_count                                                         NaN   \n",
       "park_count                                                            NaN   \n",
       "commercial_count                                                      NaN   \n",
       "government_count                                                      NaN   \n",
       "civic_count                                                           NaN   \n",
       "retail_count                                                          NaN   \n",
       "\n",
       "                                                                        4  \n",
       "Unnamed: 0                                                              4  \n",
       "geometry                POLYGON ((494818.17554479634 4141263.137357092...  \n",
       "EV_stations_counts                                                      0  \n",
       "EV_stations_geomery                                                    []  \n",
       "population                                                            0.0  \n",
       "landuse                                                             Other  \n",
       "nodes                                                                   0  \n",
       "edges                                                                   0  \n",
       "density                                                               0.0  \n",
       "oneway_exists                                                          No  \n",
       "highway_types                                                         NaN  \n",
       "average_lanes                                                         NaN  \n",
       "average_maxspeed                                                      NaN  \n",
       "city                                                              Catania  \n",
       "school_count                                                          NaN  \n",
       "university_count                                                      NaN  \n",
       "restaurant_count                                                      NaN  \n",
       "place_of_worship_count                                                NaN  \n",
       "community_centre_count                                                NaN  \n",
       "townhall_count                                                        NaN  \n",
       "parking_count                                                         NaN  \n",
       "library_count                                                         NaN  \n",
       "park_count                                                            NaN  \n",
       "commercial_count                                                      NaN  \n",
       "government_count                                                      NaN  \n",
       "civic_count                                                           NaN  \n",
       "retail_count                                                          NaN  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering out columsn to be used for modeling\n",
    "data.drop(columns=['Unnamed: 0', 'EV_stations_geomery'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size: (8534, 25)\n"
     ]
    }
   ],
   "source": [
    "print(\"data size:\" , data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all NaN values with 0\n",
    "data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geometry                  0\n",
      "EV_stations_counts        0\n",
      "population                0\n",
      "landuse                   0\n",
      "nodes                     0\n",
      "edges                     0\n",
      "density                   0\n",
      "oneway_exists             0\n",
      "highway_types             0\n",
      "average_lanes             0\n",
      "average_maxspeed          0\n",
      "city                      0\n",
      "school_count              0\n",
      "university_count          0\n",
      "restaurant_count          0\n",
      "place_of_worship_count    0\n",
      "community_centre_count    0\n",
      "townhall_count            0\n",
      "parking_count             0\n",
      "library_count             0\n",
      "park_count                0\n",
      "commercial_count          0\n",
      "government_count          0\n",
      "civic_count               0\n",
      "retail_count              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in each column\n",
    "missing_values = data.isna().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string representation of set to actual set and then to list to extract first element\n",
    "def extract_first_highway(value):\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    try:\n",
    "        # Evaluate the string as a set, convert to list and extract the first item\n",
    "        evaluated_set = eval(value)\n",
    "        if isinstance(evaluated_set, set) and evaluated_set:\n",
    "            return list(evaluated_set)[0]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Apply the function to the 'highway_types' column\n",
    "data['high_way'] = data['highway_types'].apply(extract_first_highway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, 'motorway', 'motorway_link', 'primary', 'secondary',\n",
       "       'secondary_link', 'tertiary', 'unclassified', 'residential',\n",
       "       'trunk', 'trunk_link', 'primary_link', 'tertiary_link'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code will display the unique values in the 'high_way' column.\n",
    "unique_values_highway = data['high_way'].unique()\n",
    "unique_values_highway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['geometry', 'city', 'landuse', 'oneway_exists', 'highway_types', 'high_way']\n",
    "data[categorical_columns] = data[categorical_columns].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geometry                   object\n",
       "EV_stations_counts          int64\n",
       "population                float64\n",
       "landuse                    object\n",
       "nodes                       int64\n",
       "edges                       int64\n",
       "density                   float64\n",
       "oneway_exists              object\n",
       "highway_types              object\n",
       "average_lanes             float64\n",
       "average_maxspeed          float64\n",
       "city                       object\n",
       "school_count              float64\n",
       "university_count          float64\n",
       "restaurant_count          float64\n",
       "place_of_worship_count    float64\n",
       "community_centre_count    float64\n",
       "townhall_count            float64\n",
       "parking_count             float64\n",
       "library_count             float64\n",
       "park_count                float64\n",
       "commercial_count          float64\n",
       "government_count          float64\n",
       "civic_count               float64\n",
       "retail_count              float64\n",
       "high_way                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_splitter(data, train_cities=None, test_cities=None, test_size=0.2, random_state=23):\n",
    "\n",
    "    if train_cities is not None:\n",
    "        train = data[data['city'].isin(train_cities)]\n",
    "        test = data[data['city'].isin(test_cities)]\n",
    "\n",
    "\n",
    "        X_train = train.drop(['city','geometry', 'EV_stations_counts', 'highway_types'], axis=1)\n",
    "        y_train = train['EV_stations_counts'].astype(int)\n",
    "        y_train = y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "        X_test = test.drop(['city','geometry', 'EV_stations_counts', 'highway_types'], axis=1)\n",
    "        y_test = test['EV_stations_counts'].astype(int)\n",
    "        y_test = y_test.apply(lambda x: 1 if x > 0 else 0)\n",
    "    else:\n",
    "        X = data.drop(['city','geometry', \"EV_stations_counts\", 'highway_types'], axis=1)\n",
    "        y = data['EV_stations_counts']\n",
    "        y = y.apply(lambda x: 1 if x > 0 else 0)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_splitter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Define categorical and numerical features for modelling\n",
    "categorical_features = ['landuse', 'oneway_exists', 'high_way']\n",
    "numerical_features = [col for col in X_train.columns if col not in categorical_features]\n",
    "\n",
    "# Creating a column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Fit and transform the training data, and transform the test data\n",
    "# Fitting the preprocessor on the training data and transforming training data\n",
    "X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "X_test_scaled = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy:  0.9589923842999414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1638\n",
      "           1       0.47      0.10      0.17        69\n",
      "\n",
      "    accuracy                           0.96      1707\n",
      "   macro avg       0.72      0.55      0.57      1707\n",
      "weighted avg       0.94      0.96      0.95      1707\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "print(\"Logistic Regression Test Accuracy: \", logreg.score(X_test_scaled, y_test))\n",
    "# classification report\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for CategoricalNB: index 7 is out of bounds for axis 1 with size 7\n",
      "Error occurred for ClassifierChain: ClassifierChain.__init__() missing 1 required positional argument: 'base_estimator'\n",
      "Error occurred for ComplementNB: Negative values in data passed to ComplementNB (input X)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for FixedThresholdClassifier: FixedThresholdClassifier.__init__() missing 1 required positional argument: 'estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for MultinomialNB: Negative values in data passed to MultinomialNB (input X)\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for RadiusNeighborsClassifier: No neighbors found for test samples array([   4,    6,    9,   17,   23,   27,   32,   33,   34,   37,   41,\n",
      "         46,   50,   57,   59,   65,   77,   86,   99,  102,  107,  109,\n",
      "        113,  118,  119,  123,  134,  140,  143,  145,  146,  150,  155,\n",
      "        159,  164,  166,  167,  170,  173,  182,  185,  196,  201,  206,\n",
      "        214,  218,  219,  230,  238,  239,  240,  242,  244,  245,  246,\n",
      "        258,  259,  261,  273,  274,  283,  285,  286,  291,  294,  295,\n",
      "        304,  305,  307,  310,  311,  314,  329,  335,  337,  340,  342,\n",
      "        343,  347,  348,  350,  354,  359,  368,  372,  373,  374,  375,\n",
      "        376,  377,  378,  386,  388,  391,  392,  393,  398,  420,  422,\n",
      "        423,  425,  434,  435,  438,  442,  444,  445,  446,  464,  470,\n",
      "        471,  473,  474,  479,  483,  487,  492,  493,  494,  498,  501,\n",
      "        503,  509,  521,  525,  535,  539,  544,  556,  558,  566,  569,\n",
      "        572,  573,  575,  576,  585,  596,  600,  610,  615,  617,  625,\n",
      "        626,  627,  632,  633,  637,  645,  646,  648,  649,  650,  653,\n",
      "        654,  657,  660,  661,  665,  669,  675,  683,  687,  693,  694,\n",
      "        695,  696,  704,  711,  713,  717,  732,  735,  748,  758,  761,\n",
      "        765,  767,  768,  773,  778,  782,  783,  784,  786,  789,  791,\n",
      "        793,  800,  805,  821,  822,  829,  834,  838,  839,  842,  843,\n",
      "        844,  845,  847,  851,  854,  861,  871,  880,  885,  890,  892,\n",
      "        901,  909,  916,  921,  924,  928,  936,  942,  945,  951,  953,\n",
      "        962,  968,  976,  977,  978,  979,  980,  990, 1002, 1006, 1015,\n",
      "       1017, 1021, 1024, 1027, 1030, 1036, 1047, 1058, 1062, 1070, 1076,\n",
      "       1080, 1084, 1087, 1089, 1090, 1092, 1097, 1105, 1133, 1138, 1144,\n",
      "       1146, 1151, 1157, 1159, 1164, 1168, 1171, 1178, 1189, 1194, 1199,\n",
      "       1205, 1216, 1225, 1235, 1241, 1242, 1253, 1259, 1260, 1261, 1270,\n",
      "       1275, 1276, 1278, 1280, 1282, 1284, 1285, 1288, 1293, 1296, 1302,\n",
      "       1303, 1307, 1308, 1309, 1310, 1313, 1323, 1332, 1333, 1337, 1338,\n",
      "       1351, 1357, 1360, 1365, 1377, 1379, 1381, 1384, 1385, 1386, 1399,\n",
      "       1402, 1405, 1407, 1416, 1422, 1424, 1428, 1433, 1438, 1445, 1446,\n",
      "       1450, 1452, 1456, 1471, 1479, 1488, 1489, 1498, 1501, 1504, 1528,\n",
      "       1531, 1534, 1535, 1536, 1539, 1540, 1551, 1552, 1556, 1560, 1563,\n",
      "       1567, 1570, 1573, 1576, 1577, 1585, 1593, 1596, 1598, 1617, 1620,\n",
      "       1626, 1632, 1645, 1650, 1653, 1662, 1666, 1669, 1671, 1673, 1677,\n",
      "       1688, 1691, 1692, 1693, 1698, 1703], dtype=int64), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:01<00:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for TunedThresholdClassifierCV: TunedThresholdClassifierCV.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "                             Model  Accuracy  Precision    Recall  F1-score  \\\n",
      "15      LinearDiscriminantAnalysis  0.950791   0.688051  0.703655  0.695489   \n",
      "8                       GaussianNB  0.882835   0.598632  0.793186  0.630090   \n",
      "23   QuadraticDiscriminantAnalysis  0.855888   0.586566  0.806909  0.608428   \n",
      "21     PassiveAggressiveClassifier  0.862917   0.581563  0.768926  0.603216   \n",
      "20                 NearestCentroid  0.838899   0.580603  0.811939  0.595628   \n",
      "6              ExtraTreeClassifier  0.930873   0.582468  0.596101  0.588591   \n",
      "2                      BernoulliNB  0.811951   0.577274  0.839545  0.582069   \n",
      "11  HistGradientBoostingClassifier  0.955477   0.655801  0.553392  0.575518   \n",
      "17              LogisticRegression  0.958992   0.715012  0.548283  0.572823   \n",
      "3           CalibratedClassifierCV  0.957235   0.676090  0.547367  0.569489   \n",
      "1                BaggingClassifier  0.955477   0.648280  0.546451  0.566346   \n",
      "0               AdaBoostClassifier  0.954306   0.633765  0.545841  0.564347   \n",
      "4           DecisionTreeClassifier  0.937317   0.568317  0.557812  0.562464   \n",
      "14                  LabelSpreading  0.936731   0.566845  0.557507  0.561692   \n",
      "13                LabelPropagation  0.935559   0.564045  0.556896  0.560175   \n",
      "9        GaussianProcessClassifier  0.949033   0.570227  0.529211  0.538432   \n",
      "19                   MLPClassifier  0.949033   0.570227  0.529211  0.538432   \n",
      "26               RidgeClassifierCV  0.961336   0.980634  0.521739  0.531792   \n",
      "25                 RidgeClassifier  0.960750   0.855622  0.521434  0.531069   \n",
      "16                       LinearSVC  0.960164   0.780611  0.521129  0.530361   \n",
      "27                   SGDClassifier  0.957821   0.647232  0.519908  0.527670   \n",
      "24          RandomForestClassifier  0.957235   0.630554  0.519602  0.527030   \n",
      "10      GradientBoostingClassifier  0.956063   0.605531  0.518992  0.525786   \n",
      "12            KNeighborsClassifier  0.954306   0.580496  0.518076  0.524003   \n",
      "22                      Perceptron  0.953720   0.551641  0.510830  0.512238   \n",
      "7             ExtraTreesClassifier  0.952548   0.542689  0.510219  0.511364   \n",
      "5                  DummyClassifier  0.959578   0.479789  0.500000  0.489686   \n",
      "18            LogisticRegressionCV  0.959578   0.479789  0.500000  0.489686   \n",
      "28                             SVC  0.959578   0.479789  0.500000  0.489686   \n",
      "\n",
      "         AUC  Balanced Accuracy  \n",
      "15  0.703655           0.703655  \n",
      "8   0.793186           0.793186  \n",
      "23  0.806909           0.806909  \n",
      "21  0.768926           0.768926  \n",
      "20  0.811939           0.811939  \n",
      "6   0.596101           0.596101  \n",
      "2   0.839545           0.839545  \n",
      "11  0.553392           0.553392  \n",
      "17  0.548283           0.548283  \n",
      "3   0.547367           0.547367  \n",
      "1   0.546451           0.546451  \n",
      "0   0.545841           0.545841  \n",
      "4   0.557812           0.557812  \n",
      "14  0.557507           0.557507  \n",
      "13  0.556896           0.556896  \n",
      "9   0.529211           0.529211  \n",
      "19  0.529211           0.529211  \n",
      "26  0.521739           0.521739  \n",
      "25  0.521434           0.521434  \n",
      "16  0.521129           0.521129  \n",
      "27  0.519908           0.519908  \n",
      "24  0.519602           0.519602  \n",
      "10  0.518992           0.518992  \n",
      "12  0.518076           0.518076  \n",
      "22  0.510830           0.510830  \n",
      "7   0.510219           0.510219  \n",
      "5   0.500000           0.500000  \n",
      "18  0.500000           0.500000  \n",
      "28  0.500000           0.500000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, balanced_accuracy_score\n",
    "from sklearn.utils import all_estimators\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def run_experiment(X_train, X_test, y_train, y_test):\n",
    "    # Get all classification model classes\n",
    "    classifiers = all_estimators(type_filter='classifier')\n",
    "\n",
    "    # Initialize result table\n",
    "    results = []\n",
    "    models = {}\n",
    "    # Run models and collect results\n",
    "    for name, ClassifierClass in tqdm(classifiers):\n",
    "        try:\n",
    "            # Initialize model\n",
    "            model = ClassifierClass()\n",
    "            model.fit(X_train, y_train)\n",
    "            models[name] = model\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "            recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "            f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "            auc = roc_auc_score(y_test, y_pred, multi_class='ovo')\n",
    "            balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            # Append results\n",
    "            results.append([name, accuracy, precision, recall, f1, auc, balanced_accuracy])\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred for {name}: {str(e)}\")\n",
    "\n",
    "    # Create a DataFrame from results\n",
    "    results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-score\", \"AUC\", \"Balanced Accuracy\"])\n",
    "    results_df = results_df.sort_values(by=['F1-score', 'AUC'], ascending=False)\n",
    "    return results_df, models\n",
    "\n",
    "results_df, models = run_experiment(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(X_train_scaled, X_test_scaled, y_train, y_test):\n",
    "    # Get all classification model classes\n",
    "    classifiers = all_estimators(type_filter='classifier')\n",
    "\n",
    "    # Initialize result table\n",
    "    results = []\n",
    "    models = {}\n",
    "    # Run models and collect results\n",
    "    for name, ClassifierClass in tqdm(classifiers):\n",
    "        try:\n",
    "            # Initialize model\n",
    "            model = ClassifierClass()\n",
    "            model.fit(X_train, y_train)\n",
    "            models[name] = model\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, average='macro')\n",
    "            recall = recall_score(y_test, y_pred, average='macro')\n",
    "            f1 = f1_score(y_test, y_pred, average='macro')\n",
    "            auc = roc_auc_score(y_test, y_pred)\n",
    "            balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            # Append results\n",
    "            results.append([name, accuracy, precision, recall, f1, auc, balanced_accuracy])\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred for {name}: {str(e)}\")\n",
    "\n",
    "    # Create a DataFrame from results\n",
    "    results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-score\", \"AUC\", \"Balanced Accuracy\"])\n",
    "    results_df = results_df.sort_values(by=['F1-score', 'AUC'], ascending=False)\n",
    "    return results_df, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "100%|██████████| 43/43 [00:00<00:00, 280.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for AdaBoostClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for BaggingClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for BernoulliNB: could not convert string to float: 'Other'\n",
      "Error occurred for CalibratedClassifierCV: could not convert string to float: 'Other'\n",
      "Error occurred for CategoricalNB: invalid literal for int() with base 10: 'Other'\n",
      "Error occurred for ClassifierChain: ClassifierChain.__init__() missing 1 required positional argument: 'base_estimator'\n",
      "Error occurred for ComplementNB: could not convert string to float: 'Other'\n",
      "Error occurred for DecisionTreeClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for ExtraTreeClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for ExtraTreesClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for FixedThresholdClassifier: FixedThresholdClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for GaussianNB: could not convert string to float: 'Other'\n",
      "Error occurred for GaussianProcessClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for GradientBoostingClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for HistGradientBoostingClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for KNeighborsClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for LabelPropagation: could not convert string to float: 'Other'\n",
      "Error occurred for LabelSpreading: could not convert string to float: 'Other'\n",
      "Error occurred for LinearDiscriminantAnalysis: could not convert string to float: 'Other'\n",
      "Error occurred for LinearSVC: could not convert string to float: 'Other'\n",
      "Error occurred for LogisticRegression: could not convert string to float: 'Other'\n",
      "Error occurred for LogisticRegressionCV: could not convert string to float: 'Other'\n",
      "Error occurred for MLPClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for MultinomialNB: could not convert string to float: 'Other'\n",
      "Error occurred for NearestCentroid: could not convert string to float: 'Other'\n",
      "Error occurred for NuSVC: could not convert string to float: 'Other'\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for PassiveAggressiveClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for Perceptron: could not convert string to float: 'Other'\n",
      "Error occurred for QuadraticDiscriminantAnalysis: could not convert string to float: 'Other'\n",
      "Error occurred for RadiusNeighborsClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for RandomForestClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for RidgeClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for RidgeClassifierCV: could not convert string to float: 'Other'\n",
      "Error occurred for SGDClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for SVC: could not convert string to float: 'Other'\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for TunedThresholdClassifierCV: TunedThresholdClassifierCV.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    }
   ],
   "source": [
    "result_df, models = run_experiment(X_train_scaled, X_test_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.950791</td>\n",
       "      <td>0.688051</td>\n",
       "      <td>0.703655</td>\n",
       "      <td>0.695489</td>\n",
       "      <td>0.703655</td>\n",
       "      <td>0.703655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.882835</td>\n",
       "      <td>0.598632</td>\n",
       "      <td>0.793186</td>\n",
       "      <td>0.630090</td>\n",
       "      <td>0.793186</td>\n",
       "      <td>0.793186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>0.855888</td>\n",
       "      <td>0.586566</td>\n",
       "      <td>0.806909</td>\n",
       "      <td>0.608428</td>\n",
       "      <td>0.806909</td>\n",
       "      <td>0.806909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PassiveAggressiveClassifier</td>\n",
       "      <td>0.862917</td>\n",
       "      <td>0.581563</td>\n",
       "      <td>0.768926</td>\n",
       "      <td>0.603216</td>\n",
       "      <td>0.768926</td>\n",
       "      <td>0.768926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>0.838899</td>\n",
       "      <td>0.580603</td>\n",
       "      <td>0.811939</td>\n",
       "      <td>0.595628</td>\n",
       "      <td>0.811939</td>\n",
       "      <td>0.811939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>0.930873</td>\n",
       "      <td>0.582468</td>\n",
       "      <td>0.596101</td>\n",
       "      <td>0.588591</td>\n",
       "      <td>0.596101</td>\n",
       "      <td>0.596101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.811951</td>\n",
       "      <td>0.577274</td>\n",
       "      <td>0.839545</td>\n",
       "      <td>0.582069</td>\n",
       "      <td>0.839545</td>\n",
       "      <td>0.839545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>0.955477</td>\n",
       "      <td>0.655801</td>\n",
       "      <td>0.553392</td>\n",
       "      <td>0.575518</td>\n",
       "      <td>0.553392</td>\n",
       "      <td>0.553392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.958992</td>\n",
       "      <td>0.715012</td>\n",
       "      <td>0.548283</td>\n",
       "      <td>0.572823</td>\n",
       "      <td>0.548283</td>\n",
       "      <td>0.548283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CalibratedClassifierCV</td>\n",
       "      <td>0.957235</td>\n",
       "      <td>0.676090</td>\n",
       "      <td>0.547367</td>\n",
       "      <td>0.569489</td>\n",
       "      <td>0.547367</td>\n",
       "      <td>0.547367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.955477</td>\n",
       "      <td>0.648280</td>\n",
       "      <td>0.546451</td>\n",
       "      <td>0.566346</td>\n",
       "      <td>0.546451</td>\n",
       "      <td>0.546451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.954306</td>\n",
       "      <td>0.633765</td>\n",
       "      <td>0.545841</td>\n",
       "      <td>0.564347</td>\n",
       "      <td>0.545841</td>\n",
       "      <td>0.545841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.937317</td>\n",
       "      <td>0.568317</td>\n",
       "      <td>0.557812</td>\n",
       "      <td>0.562464</td>\n",
       "      <td>0.557812</td>\n",
       "      <td>0.557812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LabelSpreading</td>\n",
       "      <td>0.936731</td>\n",
       "      <td>0.566845</td>\n",
       "      <td>0.557507</td>\n",
       "      <td>0.561692</td>\n",
       "      <td>0.557507</td>\n",
       "      <td>0.557507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LabelPropagation</td>\n",
       "      <td>0.935559</td>\n",
       "      <td>0.564045</td>\n",
       "      <td>0.556896</td>\n",
       "      <td>0.560175</td>\n",
       "      <td>0.556896</td>\n",
       "      <td>0.556896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "      <td>0.949033</td>\n",
       "      <td>0.570227</td>\n",
       "      <td>0.529211</td>\n",
       "      <td>0.538432</td>\n",
       "      <td>0.529211</td>\n",
       "      <td>0.529211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.949033</td>\n",
       "      <td>0.570227</td>\n",
       "      <td>0.529211</td>\n",
       "      <td>0.538432</td>\n",
       "      <td>0.529211</td>\n",
       "      <td>0.529211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RidgeClassifierCV</td>\n",
       "      <td>0.961336</td>\n",
       "      <td>0.980634</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.531792</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.521739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.960750</td>\n",
       "      <td>0.855622</td>\n",
       "      <td>0.521434</td>\n",
       "      <td>0.531069</td>\n",
       "      <td>0.521434</td>\n",
       "      <td>0.521434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.960164</td>\n",
       "      <td>0.780611</td>\n",
       "      <td>0.521129</td>\n",
       "      <td>0.530361</td>\n",
       "      <td>0.521129</td>\n",
       "      <td>0.521129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.957821</td>\n",
       "      <td>0.647232</td>\n",
       "      <td>0.519908</td>\n",
       "      <td>0.527670</td>\n",
       "      <td>0.519908</td>\n",
       "      <td>0.519908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.957235</td>\n",
       "      <td>0.630554</td>\n",
       "      <td>0.519602</td>\n",
       "      <td>0.527030</td>\n",
       "      <td>0.519602</td>\n",
       "      <td>0.519602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.956063</td>\n",
       "      <td>0.605531</td>\n",
       "      <td>0.518992</td>\n",
       "      <td>0.525786</td>\n",
       "      <td>0.518992</td>\n",
       "      <td>0.518992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.954306</td>\n",
       "      <td>0.580496</td>\n",
       "      <td>0.518076</td>\n",
       "      <td>0.524003</td>\n",
       "      <td>0.518076</td>\n",
       "      <td>0.518076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.953720</td>\n",
       "      <td>0.551641</td>\n",
       "      <td>0.510830</td>\n",
       "      <td>0.512238</td>\n",
       "      <td>0.510830</td>\n",
       "      <td>0.510830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.952548</td>\n",
       "      <td>0.542689</td>\n",
       "      <td>0.510219</td>\n",
       "      <td>0.511364</td>\n",
       "      <td>0.510219</td>\n",
       "      <td>0.510219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>0.959578</td>\n",
       "      <td>0.479789</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.489686</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>0.959578</td>\n",
       "      <td>0.479789</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.489686</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.959578</td>\n",
       "      <td>0.479789</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.489686</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  Accuracy  Precision    Recall  F1-score  \\\n",
       "15      LinearDiscriminantAnalysis  0.950791   0.688051  0.703655  0.695489   \n",
       "8                       GaussianNB  0.882835   0.598632  0.793186  0.630090   \n",
       "23   QuadraticDiscriminantAnalysis  0.855888   0.586566  0.806909  0.608428   \n",
       "21     PassiveAggressiveClassifier  0.862917   0.581563  0.768926  0.603216   \n",
       "20                 NearestCentroid  0.838899   0.580603  0.811939  0.595628   \n",
       "6              ExtraTreeClassifier  0.930873   0.582468  0.596101  0.588591   \n",
       "2                      BernoulliNB  0.811951   0.577274  0.839545  0.582069   \n",
       "11  HistGradientBoostingClassifier  0.955477   0.655801  0.553392  0.575518   \n",
       "17              LogisticRegression  0.958992   0.715012  0.548283  0.572823   \n",
       "3           CalibratedClassifierCV  0.957235   0.676090  0.547367  0.569489   \n",
       "1                BaggingClassifier  0.955477   0.648280  0.546451  0.566346   \n",
       "0               AdaBoostClassifier  0.954306   0.633765  0.545841  0.564347   \n",
       "4           DecisionTreeClassifier  0.937317   0.568317  0.557812  0.562464   \n",
       "14                  LabelSpreading  0.936731   0.566845  0.557507  0.561692   \n",
       "13                LabelPropagation  0.935559   0.564045  0.556896  0.560175   \n",
       "9        GaussianProcessClassifier  0.949033   0.570227  0.529211  0.538432   \n",
       "19                   MLPClassifier  0.949033   0.570227  0.529211  0.538432   \n",
       "26               RidgeClassifierCV  0.961336   0.980634  0.521739  0.531792   \n",
       "25                 RidgeClassifier  0.960750   0.855622  0.521434  0.531069   \n",
       "16                       LinearSVC  0.960164   0.780611  0.521129  0.530361   \n",
       "27                   SGDClassifier  0.957821   0.647232  0.519908  0.527670   \n",
       "24          RandomForestClassifier  0.957235   0.630554  0.519602  0.527030   \n",
       "10      GradientBoostingClassifier  0.956063   0.605531  0.518992  0.525786   \n",
       "12            KNeighborsClassifier  0.954306   0.580496  0.518076  0.524003   \n",
       "22                      Perceptron  0.953720   0.551641  0.510830  0.512238   \n",
       "7             ExtraTreesClassifier  0.952548   0.542689  0.510219  0.511364   \n",
       "5                  DummyClassifier  0.959578   0.479789  0.500000  0.489686   \n",
       "18            LogisticRegressionCV  0.959578   0.479789  0.500000  0.489686   \n",
       "28                             SVC  0.959578   0.479789  0.500000  0.489686   \n",
       "\n",
       "         AUC  Balanced Accuracy  \n",
       "15  0.703655           0.703655  \n",
       "8   0.793186           0.793186  \n",
       "23  0.806909           0.806909  \n",
       "21  0.768926           0.768926  \n",
       "20  0.811939           0.811939  \n",
       "6   0.596101           0.596101  \n",
       "2   0.839545           0.839545  \n",
       "11  0.553392           0.553392  \n",
       "17  0.548283           0.548283  \n",
       "3   0.547367           0.547367  \n",
       "1   0.546451           0.546451  \n",
       "0   0.545841           0.545841  \n",
       "4   0.557812           0.557812  \n",
       "14  0.557507           0.557507  \n",
       "13  0.556896           0.556896  \n",
       "9   0.529211           0.529211  \n",
       "19  0.529211           0.529211  \n",
       "26  0.521739           0.521739  \n",
       "25  0.521434           0.521434  \n",
       "16  0.521129           0.521129  \n",
       "27  0.519908           0.519908  \n",
       "24  0.519602           0.519602  \n",
       "10  0.518992           0.518992  \n",
       "12  0.518076           0.518076  \n",
       "22  0.510830           0.510830  \n",
       "7   0.510219           0.510219  \n",
       "5   0.500000           0.500000  \n",
       "18  0.500000           0.500000  \n",
       "28  0.500000           0.500000  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(r\"D:\\BIG_DATA\\charging_stations\\task_2\\all_cities_random_shuffle.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[AC:\\Users\\LENOVO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "100%|██████████| 43/43 [00:00<00:00, 919.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for AdaBoostClassifier: could not convert string to float: 'industrial'\n",
      "Error occurred for BaggingClassifier: could not convert string to float: 'industrial'\n",
      "Error occurred for BernoulliNB: could not convert string to float: 'industrial'\n",
      "Error occurred for CalibratedClassifierCV: could not convert string to float: 'Other'\n",
      "Error occurred for CategoricalNB: invalid literal for int() with base 10: 'industrial'\n",
      "Error occurred for ClassifierChain: ClassifierChain.__init__() missing 1 required positional argument: 'base_estimator'\n",
      "Error occurred for ComplementNB: could not convert string to float: 'industrial'\n",
      "Error occurred for DecisionTreeClassifier: could not convert string to float: 'industrial'\n",
      "Error occurred for ExtraTreeClassifier: could not convert string to float: 'industrial'\n",
      "Error occurred for ExtraTreesClassifier: could not convert string to float: 'industrial'\n",
      "Error occurred for FixedThresholdClassifier: FixedThresholdClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for GaussianNB: could not convert string to float: 'industrial'\n",
      "Error occurred for GaussianProcessClassifier: could not convert string to float: 'industrial'\n",
      "Error occurred for GradientBoostingClassifier: could not convert string to float: 'industrial'\n",
      "Error occurred for HistGradientBoostingClassifier: could not convert string to float: 'industrial'\n",
      "Error occurred for KNeighborsClassifier: could not convert string to float: 'industrial'\n",
      "Error occurred for LabelPropagation: could not convert string to float: 'industrial'\n",
      "Error occurred for LabelSpreading: could not convert string to float: 'industrial'\n",
      "Error occurred for LinearDiscriminantAnalysis: could not convert string to float: 'industrial'\n",
      "Error occurred for LinearSVC: could not convert string to float: 'industrial'\n",
      "Error occurred for LogisticRegression: could not convert string to float: 'industrial'\n",
      "Error occurred for LogisticRegressionCV: could not convert string to float: 'industrial'\n",
      "Error occurred for MLPClassifier: could not convert string to float: 'industrial'\n",
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for MultinomialNB: could not convert string to float: 'industrial'\n",
      "Error occurred for NearestCentroid: could not convert string to float: 'industrial'\n",
      "Error occurred for NuSVC: could not convert string to float: 'industrial'\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for PassiveAggressiveClassifier: could not convert string to float: 'industrial'\n",
      "Error occurred for Perceptron: could not convert string to float: 'industrial'\n",
      "Error occurred for QuadraticDiscriminantAnalysis: could not convert string to float: 'industrial'\n",
      "Error occurred for RadiusNeighborsClassifier: could not convert string to float: 'industrial'\n",
      "Error occurred for RandomForestClassifier: could not convert string to float: 'industrial'\n",
      "Error occurred for RidgeClassifier: could not convert string to float: 'industrial'\n",
      "Error occurred for RidgeClassifierCV: could not convert string to float: 'industrial'\n",
      "Error occurred for SGDClassifier: could not convert string to float: 'industrial'\n",
      "Error occurred for SVC: could not convert string to float: 'industrial'\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for TunedThresholdClassifierCV: TunedThresholdClassifierCV.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[AC:\\Users\\LENOVO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for AdaBoostClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for BaggingClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for BernoulliNB: could not convert string to float: 'Other'\n",
      "Error occurred for CalibratedClassifierCV: could not convert string to float: 'Other'\n",
      "Error occurred for CategoricalNB: invalid literal for int() with base 10: 'Other'\n",
      "Error occurred for ClassifierChain: ClassifierChain.__init__() missing 1 required positional argument: 'base_estimator'\n",
      "Error occurred for ComplementNB: could not convert string to float: 'Other'\n",
      "Error occurred for DecisionTreeClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for ExtraTreeClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for ExtraTreesClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for FixedThresholdClassifier: FixedThresholdClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for GaussianNB: could not convert string to float: 'Other'\n",
      "Error occurred for GaussianProcessClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for GradientBoostingClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for HistGradientBoostingClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for KNeighborsClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for LabelPropagation: could not convert string to float: 'Other'\n",
      "Error occurred for LabelSpreading: could not convert string to float: 'Other'\n",
      "Error occurred for LinearDiscriminantAnalysis: could not convert string to float: 'Other'\n",
      "Error occurred for LinearSVC: could not convert string to float: 'Other'\n",
      "Error occurred for LogisticRegression: could not convert string to float: 'Other'\n",
      "Error occurred for LogisticRegressionCV: could not convert string to float: 'Other'\n",
      "Error occurred for MLPClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for MultinomialNB: could not convert string to float: 'Other'\n",
      "Error occurred for NearestCentroid: could not convert string to float: 'Other'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 43/43 [00:00<00:00, 374.36it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for NuSVC: could not convert string to float: 'Other'\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for PassiveAggressiveClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for Perceptron: could not convert string to float: 'Other'\n",
      "Error occurred for QuadraticDiscriminantAnalysis: could not convert string to float: 'Other'\n",
      "Error occurred for RadiusNeighborsClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for RandomForestClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for RidgeClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for RidgeClassifierCV: could not convert string to float: 'Other'\n",
      "Error occurred for SGDClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for SVC: could not convert string to float: 'Other'\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for TunedThresholdClassifierCV: TunedThresholdClassifierCV.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for AdaBoostClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for BaggingClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for BernoulliNB: could not convert string to float: 'Other'\n",
      "Error occurred for CalibratedClassifierCV: could not convert string to float: 'Other'\n",
      "Error occurred for CategoricalNB: invalid literal for int() with base 10: 'Other'\n",
      "Error occurred for ClassifierChain: ClassifierChain.__init__() missing 1 required positional argument: 'base_estimator'\n",
      "Error occurred for ComplementNB: could not convert string to float: 'Other'\n",
      "Error occurred for DecisionTreeClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for ExtraTreeClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for ExtraTreesClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for FixedThresholdClassifier: FixedThresholdClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for GaussianNB: could not convert string to float: 'Other'\n",
      "Error occurred for GaussianProcessClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for GradientBoostingClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for HistGradientBoostingClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for KNeighborsClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for LabelPropagation: could not convert string to float: 'Other'\n",
      "Error occurred for LabelSpreading: could not convert string to float: 'Other'\n",
      "Error occurred for LinearDiscriminantAnalysis: could not convert string to float: 'Other'\n",
      "Error occurred for LinearSVC: could not convert string to float: 'Other'\n",
      "Error occurred for LogisticRegression: could not convert string to float: 'Other'\n",
      "Error occurred for LogisticRegressionCV: could not convert string to float: 'Other'\n",
      "Error occurred for MLPClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for MultinomialNB: could not convert string to float: 'Other'\n",
      "Error occurred for NearestCentroid: could not convert string to float: 'Other'\n",
      "Error occurred for NuSVC: could not convert string to float: 'Other'\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for PassiveAggressiveClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for Perceptron: could not convert string to float: 'Other'\n",
      "Error occurred for QuadraticDiscriminantAnalysis: could not convert string to float: 'Other'\n",
      "Error occurred for RadiusNeighborsClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for RandomForestClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for RidgeClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for RidgeClassifierCV: could not convert string to float: 'Other'\n",
      "Error occurred for SGDClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for SVC: could not convert string to float: 'Other'\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for TunedThresholdClassifierCV: TunedThresholdClassifierCV.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "100%|██████████| 43/43 [00:00<00:00, 904.96it/s]\n",
      "\n",
      "\u001b[AC:\\Users\\LENOVO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for AdaBoostClassifier: could not convert string to float: 'Other'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "100%|██████████| 43/43 [00:00<00:00, 512.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for BaggingClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for BernoulliNB: could not convert string to float: 'Other'\n",
      "Error occurred for CalibratedClassifierCV: could not convert string to float: 'Other'\n",
      "Error occurred for CategoricalNB: invalid literal for int() with base 10: 'Other'\n",
      "Error occurred for ClassifierChain: ClassifierChain.__init__() missing 1 required positional argument: 'base_estimator'\n",
      "Error occurred for ComplementNB: could not convert string to float: 'Other'\n",
      "Error occurred for DecisionTreeClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for ExtraTreeClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for ExtraTreesClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for FixedThresholdClassifier: FixedThresholdClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for GaussianNB: could not convert string to float: 'Other'\n",
      "Error occurred for GaussianProcessClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for GradientBoostingClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for HistGradientBoostingClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for KNeighborsClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for LabelPropagation: could not convert string to float: 'Other'\n",
      "Error occurred for LabelSpreading: could not convert string to float: 'Other'\n",
      "Error occurred for LinearDiscriminantAnalysis: could not convert string to float: 'Other'\n",
      "Error occurred for LinearSVC: could not convert string to float: 'Other'\n",
      "Error occurred for LogisticRegression: could not convert string to float: 'Other'\n",
      "Error occurred for LogisticRegressionCV: could not convert string to float: 'Other'\n",
      "Error occurred for MLPClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for MultinomialNB: could not convert string to float: 'Other'\n",
      "Error occurred for NearestCentroid: could not convert string to float: 'Other'\n",
      "Error occurred for NuSVC: could not convert string to float: 'Other'\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for PassiveAggressiveClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for Perceptron: could not convert string to float: 'Other'\n",
      "Error occurred for QuadraticDiscriminantAnalysis: could not convert string to float: 'Other'\n",
      "Error occurred for RadiusNeighborsClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for RandomForestClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for RidgeClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for RidgeClassifierCV: could not convert string to float: 'Other'\n",
      "Error occurred for SGDClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for SVC: could not convert string to float: 'Other'\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for TunedThresholdClassifierCV: TunedThresholdClassifierCV.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[AC:\\Users\\LENOVO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "100%|██████████| 43/43 [00:00<00:00, 878.63it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for AdaBoostClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for BaggingClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for BernoulliNB: could not convert string to float: 'Other'\n",
      "Error occurred for CalibratedClassifierCV: could not convert string to float: 'Other'\n",
      "Error occurred for CategoricalNB: invalid literal for int() with base 10: 'Other'\n",
      "Error occurred for ClassifierChain: ClassifierChain.__init__() missing 1 required positional argument: 'base_estimator'\n",
      "Error occurred for ComplementNB: could not convert string to float: 'Other'\n",
      "Error occurred for DecisionTreeClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for ExtraTreeClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for ExtraTreesClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for FixedThresholdClassifier: FixedThresholdClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for GaussianNB: could not convert string to float: 'Other'\n",
      "Error occurred for GaussianProcessClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for GradientBoostingClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for HistGradientBoostingClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for KNeighborsClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for LabelPropagation: could not convert string to float: 'Other'\n",
      "Error occurred for LabelSpreading: could not convert string to float: 'Other'\n",
      "Error occurred for LinearDiscriminantAnalysis: could not convert string to float: 'Other'\n",
      "Error occurred for LinearSVC: could not convert string to float: 'Other'\n",
      "Error occurred for LogisticRegression: could not convert string to float: 'Other'\n",
      "Error occurred for LogisticRegressionCV: could not convert string to float: 'Other'\n",
      "Error occurred for MLPClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for MultinomialNB: could not convert string to float: 'Other'\n",
      "Error occurred for NearestCentroid: could not convert string to float: 'Other'\n",
      "Error occurred for NuSVC: could not convert string to float: 'Other'\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for PassiveAggressiveClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for Perceptron: could not convert string to float: 'Other'\n",
      "Error occurred for QuadraticDiscriminantAnalysis: could not convert string to float: 'Other'\n",
      "Error occurred for RadiusNeighborsClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for RandomForestClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for RidgeClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for RidgeClassifierCV: could not convert string to float: 'Other'\n",
      "Error occurred for SGDClassifier: could not convert string to float: 'Other'\n",
      "Error occurred for SVC: could not convert string to float: 'Other'\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for TunedThresholdClassifierCV: TunedThresholdClassifierCV.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# List of big cities and small cities\n",
    "big_cities = ['Rome', 'Milan']\n",
    "small_cities = ['Catania', 'Florence', 'Turin']\n",
    "\n",
    "# Process for big cities\n",
    "for city in tqdm(big_cities):\n",
    "    test_cities = [city]\n",
    "    train_cities = [x for x in big_cities if x != city]\n",
    "    X_train, X_test, y_train, y_test = data_splitter(data, train_cities=train_cities, test_cities=test_cities)\n",
    "\n",
    "    # Define categorical and numerical features\n",
    "    categorical_features = ['landuse', 'oneway_exists', 'high_way']\n",
    "    numerical_features = [col for col in X_train.columns if col not in categorical_features]\n",
    "\n",
    "    # Create a column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "        ])\n",
    "    \n",
    "    # Fit and transform the training data, and transform the test data\n",
    "    X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "    X_test_scaled = preprocessor.transform(X_test)\n",
    "    results_df, models = run_experiment(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    results_df.to_csv(r\"D:\\BIG_DATA\\charging_stations\\task_2\\big_cities_test_city_{city}_.csv\", index=False)\n",
    "\n",
    "# Process for small cities\n",
    "for city in tqdm(small_cities):\n",
    "    test_cities = [city]\n",
    "    train_cities = [x for x in small_cities if x != city]\n",
    "    X_train, X_test, y_train, y_test = data_splitter(data, train_cities=train_cities, test_cities=test_cities)\n",
    "\n",
    "    # Define categorical and numerical features\n",
    "    categorical_features = ['landuse', 'oneway_exists', 'high_way']\n",
    "    numerical_features = [col for col in X_train.columns if col not in categorical_features]\n",
    "\n",
    "    # Create a column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "        ])\n",
    "    \n",
    "    # Fit and transform the training data, and transform the test data\n",
    "    X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "    X_test_scaled = preprocessor.transform(X_test)\n",
    "    results_df, models = run_experiment(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    results_df.to_csv(r\"D:\\BIG_DATA\\charging_stations\\task_2\\small_cities_test_city_{city}_.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d30a22cfa1b7409f94d93533ee7e075d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a7c626c2c1430893e6104aadff06d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for CategoricalNB: index 51 is out of bounds for axis 1 with size 51\n",
      "Error occurred for ClassifierChain: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for RadiusNeighborsClassifier: No neighbors found for test samples array([   2,    9,   17, ..., 3877, 3878, 3879]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92f17cba5294876aa74346cd90bd177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for CategoricalNB: index 53 is out of bounds for axis 1 with size 48\n",
      "Error occurred for ClassifierChain: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for RadiusNeighborsClassifier: No neighbors found for test samples array([  15,   17,   22, ..., 1409, 1410, 1420]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31475c86e0a84b208ee72addc7ee479d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for CategoricalNB: index 13 is out of bounds for axis 1 with size 10\n",
      "Error occurred for ClassifierChain: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for RadiusNeighborsClassifier: No neighbors found for test samples array([ 11,  20,  21,  23,  27,  30,  31,  32,  39,  40,  41,  42,  43,\n",
      "        44,  45,  46,  49,  50,  51,  52,  54,  55,  56,  57,  58,  59,\n",
      "        64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  77,\n",
      "        79,  80,  81,  82,  84,  85,  86,  95,  98,  99, 100, 101, 102,\n",
      "       103, 104, 106, 107, 108, 109, 110, 111, 112, 119, 122, 123, 124,\n",
      "       125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137,\n",
      "       138, 139, 144, 147, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "       159, 162, 163, 164, 165, 166, 167, 171, 172, 173, 174, 175, 176,\n",
      "       177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 189, 190, 191,\n",
      "       192, 193, 198, 199, 200, 201, 202, 203, 206, 207, 208, 209, 210,\n",
      "       211, 212, 213, 216, 219, 220, 225, 226, 227, 228, 230, 232, 233,\n",
      "       234, 235, 236, 237, 238, 239, 240, 246, 248, 250, 251, 252, 253,\n",
      "       256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269,\n",
      "       270, 271, 272, 274, 275, 277, 278, 280, 281, 282, 285, 286, 287,\n",
      "       288, 289, 290, 292, 293, 294, 295, 296, 297, 298, 299, 301, 302,\n",
      "       303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315,\n",
      "       316, 317, 318, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
      "       330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342,\n",
      "       343, 344, 346, 347, 348, 349, 350, 351, 352, 354, 355, 356, 357,\n",
      "       358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370,\n",
      "       371, 372, 373, 374, 375, 376, 377, 378, 379, 381, 382, 383, 384,\n",
      "       385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "       398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410,\n",
      "       411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423,\n",
      "       424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436,\n",
      "       437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 450,\n",
      "       451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463,\n",
      "       464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 477, 484,\n",
      "       485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497,\n",
      "       498, 499, 500, 501, 502, 503, 505, 506, 507, 509, 511, 512, 521,\n",
      "       522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534,\n",
      "       535, 536, 537, 538, 540, 541, 542, 547, 548, 549, 553, 557, 558,\n",
      "       559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571,\n",
      "       572, 573, 574, 577, 578, 579, 581, 582, 583, 585, 586, 589, 590,\n",
      "       594, 595, 596, 597, 599, 600, 601, 602, 603, 604, 605, 606, 607,\n",
      "       608, 609, 610, 611, 612, 613, 616, 617, 619, 620, 621, 622, 623,\n",
      "       624, 625, 626, 627, 628, 632, 633, 634, 635, 636, 637, 638, 639,\n",
      "       640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 652, 654,\n",
      "       655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667,\n",
      "       669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681,\n",
      "       682, 683, 684, 685, 686, 687, 688, 689, 691, 692, 693, 694, 695,\n",
      "       696, 697, 699, 701, 703, 704, 705, 706, 707, 708, 709, 710, 711,\n",
      "       712, 713, 714, 715, 716, 717, 718, 719, 720, 722, 723, 724, 725,\n",
      "       727, 728, 729, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743,\n",
      "       744, 745, 746, 747, 748, 749, 750, 751, 752, 754, 755, 757, 758,\n",
      "       759, 760, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772,\n",
      "       773, 774, 775, 776, 777, 778, 779, 780, 782, 783, 784, 785, 786,\n",
      "       794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806,\n",
      "       808, 809, 810, 812, 813, 814, 815, 816, 823, 824, 825, 826, 827,\n",
      "       828, 829, 830, 831, 832, 836, 837, 838, 839, 840, 841, 842, 843,\n",
      "       844, 845, 846, 847, 848, 850, 851, 853, 854, 855, 856, 857, 858,\n",
      "       859, 861, 863, 864, 865, 866, 867, 868, 869, 873, 874, 875, 876,\n",
      "       878, 880, 887, 901, 902, 903, 904, 905, 906, 907, 910, 911, 912,\n",
      "       913, 914, 929, 930, 933, 934, 938, 939, 941, 956]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030ce01784024886a760291e74713e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for CategoricalNB: index 12 is out of bounds for axis 1 with size 11\n",
      "Error occurred for ClassifierChain: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for RadiusNeighborsClassifier: No neighbors found for test samples array([   6,   12,   13,   19,   20,   21,   27,   28,   29,   30,   31,\n",
      "         32,   33,   41,   43,   44,   45,   46,   55,   56,   57,   58,\n",
      "         59,   60,   61,   66,   67,   68,   69,   70,   71,   79,   80,\n",
      "         81,   82,   83,   84,   86,   88,   89,   90,   91,   92,   93,\n",
      "         94,   95,   96,   97,  101,  102,  103,  104,  105,  106,  107,\n",
      "        108,  109,  110,  115,  116,  117,  118,  120,  121,  122,  123,\n",
      "        129,  130,  136,  138,  139,  141,  142,  153,  154,  159,  160,\n",
      "        162,  163,  164,  165,  166,  167,  168,  171,  178,  179,  186,\n",
      "        187,  188,  189,  192,  193,  194,  195,  196,  197,  204,  205,\n",
      "        206,  210,  213,  215,  216,  219,  220,  221,  222,  223,  224,\n",
      "        225,  226,  227,  232,  238,  239,  243,  244,  245,  249,  250,\n",
      "        251,  253,  254,  260,  261,  265,  266,  267,  270,  273,  274,\n",
      "        275,  276,  279,  280,  281,  282,  283,  284,  285,  286,  291,\n",
      "        292,  296,  303,  305,  306,  307,  308,  309,  310,  311,  312,\n",
      "        313,  314,  315,  316,  317,  318,  319,  320,  324,  325,  326,\n",
      "        336,  337,  338,  339,  340,  341,  342,  343,  344,  345,  346,\n",
      "        347,  348,  349,  351,  352,  357,  364,  365,  366,  367,  368,\n",
      "        369,  370,  371,  372,  373,  374,  375,  376,  377,  378,  379,\n",
      "        380,  381,  382,  383,  384,  385,  386,  394,  396,  397,  398,\n",
      "        399,  400,  401,  402,  403,  404,  405,  406,  407,  408,  409,\n",
      "        410,  411,  412,  413,  414,  415,  416,  417,  418,  419,  420,\n",
      "        425,  426,  428,  429,  430,  431,  432,  433,  434,  435,  436,\n",
      "        438,  439,  440,  441,  442,  443,  444,  445,  446,  447,  448,\n",
      "        449,  450,  451,  452,  453,  455,  459,  462,  463,  464,  465,\n",
      "        466,  467,  468,  469,  470,  471,  472,  473,  474,  475,  476,\n",
      "        477,  478,  479,  480,  481,  482,  483,  484,  485,  486,  487,\n",
      "        488,  489,  490,  494,  496,  497,  498,  499,  500,  502,  503,\n",
      "        504,  505,  506,  507,  508,  509,  510,  511,  512,  513,  514,\n",
      "        515,  516,  517,  518,  519,  520,  521,  522,  523,  524,  525,\n",
      "        527,  530,  531,  532,  533,  535,  538,  539,  540,  541,  542,\n",
      "        543,  544,  545,  546,  547,  548,  549,  550,  551,  552,  553,\n",
      "        554,  555,  556,  557,  558,  559,  560,  561,  562,  566,  567,\n",
      "        568,  569,  570,  571,  573,  574,  575,  576,  577,  578,  579,\n",
      "        580,  581,  582,  583,  584,  585,  586,  587,  588,  589,  590,\n",
      "        591,  592,  593,  594,  596,  602,  603,  604,  605,  606,  607,\n",
      "        608,  610,  611,  612,  613,  614,  615,  616,  617,  618,  619,\n",
      "        620,  621,  622,  623,  624,  625,  626,  627,  628,  629,  631,\n",
      "        638,  639,  640,  642,  643,  644,  647,  648,  649,  650,  651,\n",
      "        652,  653,  654,  655,  656,  657,  658,  659,  660,  661,  662,\n",
      "        663,  664,  665,  666,  667,  670,  672,  676,  677,  683,  684,\n",
      "        685,  686,  687,  688,  689,  690,  691,  692,  693,  694,  695,\n",
      "        696,  697,  698,  699,  700,  701,  702,  703,  704,  706,  709,\n",
      "        718,  722,  723,  724,  725,  726,  727,  728,  729,  730,  731,\n",
      "        732,  733,  734,  735,  736,  737,  738,  739,  740,  741,  744,\n",
      "        746,  747,  755,  756,  758,  759,  760,  761,  762,  763,  764,\n",
      "        765,  766,  767,  768,  769,  770,  771,  772,  773,  774,  775,\n",
      "        776,  777,  778,  784,  787,  788,  791,  792,  793,  794,  795,\n",
      "        798,  799,  800,  801,  802,  803,  804,  805,  806,  807,  808,\n",
      "        809,  810,  811,  812,  813,  814,  815,  824,  825,  826,  836,\n",
      "        837,  838,  866,  867,  868,  869,  870,  871,  872,  873,  874,\n",
      "        875,  876,  877,  878,  879,  880,  881,  894,  895,  896,  897,\n",
      "        898,  899,  900,  901,  902,  903,  904,  905,  906,  907,  909,\n",
      "        912,  917,  918,  919,  922,  923,  924,  925,  926,  927,  928,\n",
      "        929,  930,  931,  932,  933,  934,  937,  939,  941,  943,  944,\n",
      "        945,  946,  948,  949,  950,  951,  952,  953,  955,  956,  957,\n",
      "        966,  967,  968,  969,  970,  971,  972,  973,  974,  975,  976,\n",
      "        978,  979,  980,  981,  982,  983,  984,  985,  986,  987,  988,\n",
      "        992,  993,  994,  995,  996,  997,  998,  999, 1000, 1001, 1006,\n",
      "       1007, 1008, 1009, 1010, 1012, 1013, 1014, 1015, 1016, 1023, 1024,\n",
      "       1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1040, 1045,\n",
      "       1046, 1047, 1048, 1049, 1050, 1051, 1058, 1063, 1068, 1072, 1084,\n",
      "       1091, 1092, 1093, 1094, 1100, 1105, 1121, 1129, 1130, 1137, 1143,\n",
      "       1145]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc46bee2e1040c887bd0439a1a1f83a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25c68000bcf4b258b3d1a9148f922c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for AdaBoostClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by AdaBoostClassifier.\n",
      "Error occurred for BaggingClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by BaggingClassifier.\n",
      "Error occurred for BernoulliNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by BernoulliNB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/lib/function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/lib/function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/lib/function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/lib/function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for CalibratedClassifierCV: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LinearSVC.\n",
      "Error occurred for CategoricalNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by CategoricalNB.\n",
      "Error occurred for ClassifierChain: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n",
      "Error occurred for ComplementNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by ComplementNB.\n",
      "Error occurred for DecisionTreeClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by DecisionTreeClassifier.\n",
      "Error occurred for DummyClassifier: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "Error occurred for ExtraTreeClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by ExtraTreeClassifier.\n",
      "Error occurred for ExtraTreesClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by ExtraTreesClassifier.\n",
      "Error occurred for GaussianNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by GaussianNB.\n",
      "Error occurred for GaussianProcessClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by GaussianProcessClassifier.\n",
      "Error occurred for GradientBoostingClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by GradientBoostingClassifier.\n",
      "Error occurred for HistGradientBoostingClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by HistGradientBoostingClassifier.\n",
      "Error occurred for KNeighborsClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by KNeighborsClassifier.\n",
      "Error occurred for LabelPropagation: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LabelPropagation.\n",
      "Error occurred for LabelSpreading: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LabelSpreading.\n",
      "Error occurred for LinearDiscriminantAnalysis: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LinearDiscriminantAnalysis.\n",
      "Error occurred for LinearSVC: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LinearSVC.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for LogisticRegression: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LogisticRegression.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for LogisticRegressionCV: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LogisticRegressionCV.\n",
      "Error occurred for MLPClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by MLPClassifier.\n",
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for MultinomialNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by MultinomialNB.\n",
      "Error occurred for NearestCentroid: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by NearestCentroid.\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for PassiveAggressiveClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by PassiveAggressiveClassifier.\n",
      "Error occurred for Perceptron: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by Perceptron.\n",
      "Error occurred for QuadraticDiscriminantAnalysis: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by QuadraticDiscriminantAnalysis.\n",
      "Error occurred for RadiusNeighborsClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by RadiusNeighborsClassifier.\n",
      "Error occurred for RandomForestClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by RandomForestClassifier.\n",
      "Error occurred for RidgeClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by RidgeClassifier.\n",
      "Error occurred for RidgeClassifierCV: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by RidgeClassifierCV.\n",
      "Error occurred for SGDClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by SGDClassifier.\n",
      "Error occurred for SVC: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by SVC.\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb4569a91ae4d588c9f53a46a8252b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for CategoricalNB: index 87 is out of bounds for axis 1 with size 46\n",
      "Error occurred for ClassifierChain: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for RadiusNeighborsClassifier: No neighbors found for test samples array([  7,  11,  15,  21,  25,  27,  28,  29,  39,  40,  41,  42,  43,\n",
      "        47,  51,  52,  53,  54,  55,  58,  59,  63,  64,  65,  66,  70,\n",
      "        71,  72,  73,  74,  75,  76,  82,  83,  84,  85,  86,  87,  88,\n",
      "        90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 102, 103, 104,\n",
      "       105, 106, 107, 108, 109, 110, 112, 115, 116, 120, 121, 122, 123,\n",
      "       124, 125, 126, 127, 128, 129, 130, 131, 133, 135, 137, 138, 139,\n",
      "       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153,\n",
      "       154, 155, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
      "       172, 182, 183, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "       196, 197, 208, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "       220, 221, 230, 231, 236, 237, 238, 239, 240, 241, 242, 243, 244,\n",
      "       245, 246, 247, 248, 262, 263, 264, 265, 266, 267, 268, 269, 270,\n",
      "       271, 272, 273, 275, 279, 284, 285, 288, 290, 291, 292, 293, 294,\n",
      "       295, 296, 297, 298, 299, 300, 301, 302, 303, 319, 320, 324, 325,\n",
      "       326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338,\n",
      "       339, 340, 341, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 386,\n",
      "       387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 399, 408,\n",
      "       409, 410, 411, 413, 414, 415, 416, 417, 418, 419, 426, 427, 428,\n",
      "       429, 432, 434, 435, 436, 437, 443, 444, 445, 446, 450, 453, 456,\n",
      "       470, 471, 472, 473, 474, 477, 478, 479, 480, 481, 483, 484, 486,\n",
      "       487, 488, 497, 498, 499, 500, 501, 502, 503, 504, 505, 507, 510,\n",
      "       511, 512, 513, 514, 515, 516, 517, 518, 524, 525, 526, 527, 528,\n",
      "       529, 538, 539, 540, 554, 563, 564, 569, 570, 578, 581, 582]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e259d8affbc14a86933d3b6ad8dfe4e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for AdaBoostClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by AdaBoostClassifier.\n",
      "Error occurred for BaggingClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by BaggingClassifier.\n",
      "Error occurred for BernoulliNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by BernoulliNB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/lib/function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/lib/function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/lib/function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/lib/function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for CalibratedClassifierCV: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LinearSVC.\n",
      "Error occurred for CategoricalNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by CategoricalNB.\n",
      "Error occurred for ClassifierChain: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n",
      "Error occurred for ComplementNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by ComplementNB.\n",
      "Error occurred for DecisionTreeClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by DecisionTreeClassifier.\n",
      "Error occurred for DummyClassifier: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "Error occurred for ExtraTreeClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by ExtraTreeClassifier.\n",
      "Error occurred for ExtraTreesClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by ExtraTreesClassifier.\n",
      "Error occurred for GaussianNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by GaussianNB.\n",
      "Error occurred for GaussianProcessClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by GaussianProcessClassifier.\n",
      "Error occurred for GradientBoostingClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by GradientBoostingClassifier.\n",
      "Error occurred for HistGradientBoostingClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by HistGradientBoostingClassifier.\n",
      "Error occurred for KNeighborsClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by KNeighborsClassifier.\n",
      "Error occurred for LabelPropagation: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LabelPropagation.\n",
      "Error occurred for LabelSpreading: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LabelSpreading.\n",
      "Error occurred for LinearDiscriminantAnalysis: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LinearDiscriminantAnalysis.\n",
      "Error occurred for LinearSVC: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LinearSVC.\n",
      "Error occurred for LogisticRegression: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LogisticRegression.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for LogisticRegressionCV: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LogisticRegressionCV.\n",
      "Error occurred for MLPClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by MLPClassifier.\n",
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for MultinomialNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by MultinomialNB.\n",
      "Error occurred for NearestCentroid: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by NearestCentroid.\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for PassiveAggressiveClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by PassiveAggressiveClassifier.\n",
      "Error occurred for Perceptron: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by Perceptron.\n",
      "Error occurred for QuadraticDiscriminantAnalysis: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by QuadraticDiscriminantAnalysis.\n",
      "Error occurred for RadiusNeighborsClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by RadiusNeighborsClassifier.\n",
      "Error occurred for RandomForestClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by RandomForestClassifier.\n",
      "Error occurred for RidgeClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by RidgeClassifier.\n",
      "Error occurred for RidgeClassifierCV: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by RidgeClassifierCV.\n",
      "Error occurred for SGDClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by SGDClassifier.\n",
      "Error occurred for SVC: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by SVC.\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd1531cae544ac7847a04ad5bc101ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for CategoricalNB: index 47 is out of bounds for axis 1 with size 33\n",
      "Error occurred for ClassifierChain: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/semi_supervised/_label_propagation.py:222: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for RadiusNeighborsClassifier: No neighbors found for test samples array([  0,   2,   3,   8,  11,  12,  14,  16,  17,  19,  21,  22,  24,\n",
      "        26,  27,  28,  29,  30,  33,  35,  36,  37,  38,  39,  40,  43,\n",
      "        44,  45,  46,  47,  48,  49,  50,  54,  56,  57,  58,  59,  60,\n",
      "        61,  62,  63,  64,  65,  66,  67,  68,  72,  73,  74,  75,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  86,  87,  89,  90,  91,  92,\n",
      "        93,  94,  95,  97,  98,  99, 101, 102, 104, 105, 106, 107, 108,\n",
      "       110, 111, 112, 113, 114, 115, 116, 120, 121, 122, 125, 126, 127,\n",
      "       128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 140, 141, 142,\n",
      "       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "       159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173,\n",
      "       174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 186, 187, 188,\n",
      "       189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201,\n",
      "       202, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217,\n",
      "       218, 219, 220, 221, 222, 231, 232, 233, 236, 238, 239, 240, 241,\n",
      "       242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254,\n",
      "       255, 256, 257, 261, 262, 263, 264, 269, 270, 271, 272, 273, 274,\n",
      "       275, 276, 277, 278, 279, 281, 282, 283, 284, 285, 286, 287, 288,\n",
      "       292, 293, 294, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306,\n",
      "       307, 308, 309, 310, 311, 312, 313, 318, 319, 322, 323, 324, 325,\n",
      "       326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 337, 338, 339,\n",
      "       344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356,\n",
      "       357, 360, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374,\n",
      "       375, 379, 380, 381, 382, 383, 384, 385, 386, 391, 392, 393, 394,\n",
      "       395, 398, 400, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415,\n",
      "       416, 417, 418, 419, 420, 421, 422, 423, 426, 427, 428, 429, 430,\n",
      "       431, 432, 434, 435, 436, 437, 438, 439, 440, 445, 446, 447, 448,\n",
      "       455, 456, 457, 466, 467, 468, 475, 476, 484, 486, 487]), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/anaconda3/envs/condaenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Rome, Milan: Big CITY EXP-1\n",
    "Turin, Florence, Catania: EXP-2\n",
    "\"\"\"\n",
    "\n",
    "# EXP-1\n",
    "big_cities = ['Rome', 'Milan']\n",
    "small_cities = ['Catania', 'Florence', 'Turin']\n",
    "\n",
    "\n",
    "# make a table in the end to summarise the results of all experiments\n",
    "\n",
    "# big cities splited in train and test where only one big city is test and all possible combinations for this\n",
    "for city in tqdm(big_cities):\n",
    "    test_cities = [city]\n",
    "    train_cities = [x for x in big_cities if x != city]\n",
    "    X_train, X_test, y_train, y_test = data_splitter(data, train_cities=train_cities, test_cities=test_cities)\n",
    "    results_df, models = run_experiment(X_train, X_test, y_train, y_test)\n",
    "    results_df.to_csv(r\"charging_stations/task_2/big_cities_test_city_{city}_.csv\", index=False)\n",
    "    \n",
    "\n",
    "# small cities splited in train and test where only one small city is test and all possible combinations for this\n",
    "for city in tqdm(small_cities):\n",
    "    test_cities = [city]\n",
    "    train_cities = [x for x in small_cities if x != city]\n",
    "    X_train, X_test, y_train, y_test = data_splitter(data, train_cities=train_cities, test_cities=test_cities)\n",
    "    results_df, models = run_experiment(X_train, X_test, y_train, y_test)\n",
    "    results_df.to_csv(r\"charging_stations/task_2/small_cities_test_city_{city}_.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>0.868637</td>\n",
       "      <td>0.434319</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.464851</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model  Accuracy  Precision  Recall  F1-score  AUC  \\\n",
       "0  DummyClassifier  0.868637   0.434319     0.5  0.464851  0.5   \n",
       "\n",
       "   Balanced Accuracy  \n",
       "0                0.5  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/all_cities_random_shuffle.csv\n",
      "/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/small_cities_test_city_Mainz_.csv\n",
      "/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/small_cities_test_city_Trier_.csv\n",
      "/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/big_cities_test_city_Munich_.csv\n",
      "/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/big_cities_test_city_Berlin_.csv\n",
      "/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/small_cities_test_city_Saarbrücken_.csv\n",
      "/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/big_cities_test_city_Stuttgart_.csv\n",
      "/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/small_cities_test_city_Karlsruhe_.csv\n",
      "/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/big_cities_test_city_Frankfurt_.csv\n",
      "                     Model  Average AUC\n",
      "1              BernoulliNB     0.784188\n",
      "13         NearestCentroid     0.767735\n",
      "8             ComplementNB     0.661513\n",
      "4            MultinomialNB     0.657249\n",
      "0   DecisionTreeClassifier     0.643120\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Get a list of all result files from different experiments\n",
    "result_files = glob.glob(\"/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/*.csv\")\n",
    "\n",
    "# Create a dictionary to store the total AUC and count for each model\n",
    "auc_sum_per_model = {}\n",
    "count_per_model = {}\n",
    "\n",
    "# Iterate over each result file\n",
    "for file in result_files:\n",
    "    print(file)\n",
    "    # Load the results for each experiment\n",
    "    results = pd.read_csv(file)\n",
    "    \n",
    "    # Iterate over each row in the results\n",
    "    for _, row in results.iterrows():\n",
    "        model = row['Model']\n",
    "        auc = row['AUC']\n",
    "        \n",
    "        # Update the total AUC and count for the model\n",
    "        if model in auc_sum_per_model:\n",
    "            auc_sum_per_model[model] += auc\n",
    "            count_per_model[model] += 1\n",
    "        else:\n",
    "            auc_sum_per_model[model] = auc\n",
    "            count_per_model[model] = 1\n",
    "\n",
    "# Calculate the average AUC for each model\n",
    "average_auc_per_model = {model: auc_sum_per_model[model] / count_per_model[model] for model in auc_sum_per_model}\n",
    "\n",
    "# Create a DataFrame from the average AUC dictionary\n",
    "average_auc_df = pd.DataFrame(list(average_auc_per_model.items()), columns=['Model', 'Average AUC'])\n",
    "\n",
    "# Sort the DataFrame by Average AUC in descending order\n",
    "sorted_models = average_auc_df.sort_values(by='Average AUC', ascending=False)\n",
    "\n",
    "# Select the top 5 models\n",
    "top_5_models = sorted_models.head(5)\n",
    "\n",
    "# Display the best models\n",
    "print(top_5_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BernoulliNB',\n",
       " 'NearestCentroid',\n",
       " 'ComplementNB',\n",
       " 'MultinomialNB',\n",
       " 'DecisionTreeClassifier']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  type_city  BernoulliNB  ComplementNB  DecisionTreeClassifier  MultinomialNB  \\\n",
      "0       big     0.764115      0.669090                0.621317       0.653853   \n",
      "1     small     0.810223      0.654498                0.681870       0.666221   \n",
      "2       all     0.810952      0.651410                0.672189       0.661778   \n",
      "\n",
      "   NearestCentroid  \n",
      "0         0.715620  \n",
      "1         0.853362  \n",
      "2         0.837221  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_386664/2782532669.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/2782532669.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/2782532669.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/2782532669.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/2782532669.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  summary_results = summary_results.append(row, ignore_index=True)\n",
      "/tmp/ipykernel_386664/2782532669.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/2782532669.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/2782532669.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/2782532669.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/2782532669.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  summary_results = summary_results.append(row, ignore_index=True)\n",
      "/tmp/ipykernel_386664/2782532669.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/2782532669.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/2782532669.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/2782532669.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/2782532669.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/2782532669.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  summary_results = summary_results.append(row, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Get a list of all result files from different experiments\n",
    "result_files = glob.glob(\"/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/*.csv\")\n",
    "\n",
    "# Create an empty DataFrame to store the combined results\n",
    "combined_results = pd.DataFrame()\n",
    "\n",
    "# Create an empty DataFrame to store the summary\n",
    "summary_results = pd.DataFrame(columns=['type_city'])\n",
    "\n",
    "# Iterate over each result file\n",
    "for type_city in ['big', 'small', 'all']:\n",
    "    # Reset combined_results for each type_city iteration\n",
    "    combined_results = pd.DataFrame()\n",
    "\n",
    "    # Iterate over each result file\n",
    "    for file in result_files:\n",
    "        # Load the results for each experiment\n",
    "        if type_city in file:\n",
    "            results = pd.read_csv(file)\n",
    "            \n",
    "            # Append the results to the combined DataFrame\n",
    "            combined_results = combined_results.append(results)\n",
    "\n",
    "    # Calculate the average AUC for each model\n",
    "    average_auc_per_model = combined_results.groupby('Model')['AUC'].mean()\n",
    "    \n",
    "    # Sort the models by average AUC in descending order\n",
    "    sorted_models = average_auc_per_model.sort_values(ascending=False)\n",
    "    \n",
    "    # Filter the results to include only the rows corresponding to the top 5 models\n",
    "    filtered_results = combined_results[combined_results['Model'].isin(top_5_models)]\n",
    "\n",
    "    # Calculate the average AUC for each model\n",
    "    average_auc_by_model = filtered_results.groupby('Model')['AUC'].mean()\n",
    "    \n",
    "    # Create a row with type_city and average AUC values for each model\n",
    "    row = {'type_city': type_city}\n",
    "    row.update(average_auc_by_model)\n",
    "    \n",
    "    # Append the row to the summary_results DataFrame\n",
    "    summary_results = summary_results.append(row, ignore_index=True)\n",
    "\n",
    "# Display the summary_results DataFrame\n",
    "print(summary_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_city</th>\n",
       "      <th>BernoulliNB</th>\n",
       "      <th>ComplementNB</th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <th>NearestCentroid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>big</td>\n",
       "      <td>0.764115</td>\n",
       "      <td>0.669090</td>\n",
       "      <td>0.621317</td>\n",
       "      <td>0.653853</td>\n",
       "      <td>0.715620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>small</td>\n",
       "      <td>0.810223</td>\n",
       "      <td>0.654498</td>\n",
       "      <td>0.681870</td>\n",
       "      <td>0.666221</td>\n",
       "      <td>0.853362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all</td>\n",
       "      <td>0.810952</td>\n",
       "      <td>0.651410</td>\n",
       "      <td>0.672189</td>\n",
       "      <td>0.661778</td>\n",
       "      <td>0.837221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type_city  BernoulliNB  ComplementNB  DecisionTreeClassifier  MultinomialNB  \\\n",
       "0       big     0.764115      0.669090                0.621317       0.653853   \n",
       "1     small     0.810223      0.654498                0.681870       0.666221   \n",
       "2       all     0.810952      0.651410                0.672189       0.661778   \n",
       "\n",
       "   NearestCentroid  \n",
       "0         0.715620  \n",
       "1         0.853362  \n",
       "2         0.837221  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_386664/1572437187.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/1572437187.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/1572437187.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/1572437187.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/1572437187.py:31: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  average_metrics_per_model = filtered_results.groupby('Model')['AUC', 'Accuracy', 'Precision', 'Recall'].mean()\n",
      "/tmp/ipykernel_386664/1572437187.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  summary_results = summary_results.append(row, ignore_index=True)\n",
      "/tmp/ipykernel_386664/1572437187.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/1572437187.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/1572437187.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/1572437187.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/1572437187.py:31: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  average_metrics_per_model = filtered_results.groupby('Model')['AUC', 'Accuracy', 'Precision', 'Recall'].mean()\n",
      "/tmp/ipykernel_386664/1572437187.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  summary_results = summary_results.append(row, ignore_index=True)\n",
      "/tmp/ipykernel_386664/1572437187.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/1572437187.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/1572437187.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/1572437187.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/1572437187.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_results = combined_results.append(results)\n",
      "/tmp/ipykernel_386664/1572437187.py:31: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  average_metrics_per_model = filtered_results.groupby('Model')['AUC', 'Accuracy', 'Precision', 'Recall'].mean()\n",
      "/tmp/ipykernel_386664/1572437187.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  summary_results = summary_results.append(row, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_city</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>big</td>\n",
       "      <td>0.684799</td>\n",
       "      <td>0.813313</td>\n",
       "      <td>0.649200</td>\n",
       "      <td>0.684799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>small</td>\n",
       "      <td>0.733235</td>\n",
       "      <td>0.884658</td>\n",
       "      <td>0.617062</td>\n",
       "      <td>0.733235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all</td>\n",
       "      <td>0.726710</td>\n",
       "      <td>0.876493</td>\n",
       "      <td>0.621050</td>\n",
       "      <td>0.726710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type_city       AUC  Accuracy  Precision    Recall\n",
       "0       big  0.684799  0.813313   0.649200  0.684799\n",
       "1     small  0.733235  0.884658   0.617062  0.733235\n",
       "2       all  0.726710  0.876493   0.621050  0.726710"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Get a list of all result files from different experiments\n",
    "result_files = glob.glob(\"/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/*.csv\")\n",
    "\n",
    "# Create an empty DataFrame to store the combined results\n",
    "combined_results = pd.DataFrame()\n",
    "\n",
    "# Create an empty DataFrame to store the summary\n",
    "summary_results = pd.DataFrame(columns=['type_city', 'AUC', 'Accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "# Iterate over each result file\n",
    "for type_city in ['big', 'small', 'all']:\n",
    "    # Reset combined_results for each type_city iteration\n",
    "    combined_results = pd.DataFrame()\n",
    "\n",
    "    # Iterate over each result file\n",
    "    for file in result_files:\n",
    "        # Load the results for each experiment\n",
    "        if type_city in file:\n",
    "            results = pd.read_csv(file)\n",
    "            \n",
    "            # Append the results to the combined DataFrame\n",
    "            combined_results = combined_results.append(results)\n",
    "\n",
    "    # Filter the results to include only the rows corresponding to the top 5 models\n",
    "    filtered_results = combined_results[combined_results['Model'].isin(top_5_models)]\n",
    "\n",
    "    # Calculate the average values for each metric\n",
    "    average_metrics_per_model = filtered_results.groupby('Model')['AUC', 'Accuracy', 'Precision', 'Recall'].mean()\n",
    "\n",
    "    # Calculate the average values for each metric\n",
    "    average_values = average_metrics_per_model.mean()\n",
    "\n",
    "    # Create a row with type_city, average values for each metric\n",
    "    row = {'type_city': type_city}\n",
    "    for metric in ['AUC', 'Accuracy', 'Precision', 'Recall']:\n",
    "        row[metric] = average_values[metric]\n",
    "\n",
    "    # Append the row to the summary_results DataFrame\n",
    "    summary_results = summary_results.append(row, ignore_index=True)\n",
    "\n",
    "# Display the summary_results DataFrame\n",
    "summary_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BernoulliNB',\n",
       " 'NearestCentroid',\n",
       " 'ComplementNB',\n",
       " 'MultinomialNB',\n",
       " 'DecisionTreeClassifier']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_results.to_csv(\"/home/bahramkhanbaloch/media3/MS/Semester1/DS/results/summary_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
